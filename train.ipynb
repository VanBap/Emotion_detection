{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nss-17/Face-tracking-Emotion-detection-Eye-tracking/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PONqq6h1j-5Y",
        "outputId": "37703568-622a-481a-8f16-8789dfde16bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import MobileNet\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten,GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D,MaxPooling2D,ZeroPadding2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "NQzZtG06p7Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MobileNet is designed to work with images of dim 224,224\n",
        "img_rows,img_cols = 224,224\n"
      ],
      "metadata": {
        "id": "pJZ09OC8qNel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNet = MobileNet(weights='imagenet',include_top=False,input_shape=(img_rows,img_cols,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD9xf_lwqTxd",
        "outputId": "8eb7c424-110f-4159-ca14-d70f1c83e0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in MobileNet.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Let's print our layers\n",
        "for (i,layer) in enumerate(MobileNet.layers):\n",
        "    print(str(i),layer.__class__.__name__,layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWs1MzCtqbTA",
        "outputId": "d9fd5949-eac6-49c0-85b1-556b94e5c950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 InputLayer True\n",
            "1 Conv2D True\n",
            "2 BatchNormalization True\n",
            "3 ReLU True\n",
            "4 DepthwiseConv2D True\n",
            "5 BatchNormalization True\n",
            "6 ReLU True\n",
            "7 Conv2D True\n",
            "8 BatchNormalization True\n",
            "9 ReLU True\n",
            "10 ZeroPadding2D True\n",
            "11 DepthwiseConv2D True\n",
            "12 BatchNormalization True\n",
            "13 ReLU True\n",
            "14 Conv2D True\n",
            "15 BatchNormalization True\n",
            "16 ReLU True\n",
            "17 DepthwiseConv2D True\n",
            "18 BatchNormalization True\n",
            "19 ReLU True\n",
            "20 Conv2D True\n",
            "21 BatchNormalization True\n",
            "22 ReLU True\n",
            "23 ZeroPadding2D True\n",
            "24 DepthwiseConv2D True\n",
            "25 BatchNormalization True\n",
            "26 ReLU True\n",
            "27 Conv2D True\n",
            "28 BatchNormalization True\n",
            "29 ReLU True\n",
            "30 DepthwiseConv2D True\n",
            "31 BatchNormalization True\n",
            "32 ReLU True\n",
            "33 Conv2D True\n",
            "34 BatchNormalization True\n",
            "35 ReLU True\n",
            "36 ZeroPadding2D True\n",
            "37 DepthwiseConv2D True\n",
            "38 BatchNormalization True\n",
            "39 ReLU True\n",
            "40 Conv2D True\n",
            "41 BatchNormalization True\n",
            "42 ReLU True\n",
            "43 DepthwiseConv2D True\n",
            "44 BatchNormalization True\n",
            "45 ReLU True\n",
            "46 Conv2D True\n",
            "47 BatchNormalization True\n",
            "48 ReLU True\n",
            "49 DepthwiseConv2D True\n",
            "50 BatchNormalization True\n",
            "51 ReLU True\n",
            "52 Conv2D True\n",
            "53 BatchNormalization True\n",
            "54 ReLU True\n",
            "55 DepthwiseConv2D True\n",
            "56 BatchNormalization True\n",
            "57 ReLU True\n",
            "58 Conv2D True\n",
            "59 BatchNormalization True\n",
            "60 ReLU True\n",
            "61 DepthwiseConv2D True\n",
            "62 BatchNormalization True\n",
            "63 ReLU True\n",
            "64 Conv2D True\n",
            "65 BatchNormalization True\n",
            "66 ReLU True\n",
            "67 DepthwiseConv2D True\n",
            "68 BatchNormalization True\n",
            "69 ReLU True\n",
            "70 Conv2D True\n",
            "71 BatchNormalization True\n",
            "72 ReLU True\n",
            "73 ZeroPadding2D True\n",
            "74 DepthwiseConv2D True\n",
            "75 BatchNormalization True\n",
            "76 ReLU True\n",
            "77 Conv2D True\n",
            "78 BatchNormalization True\n",
            "79 ReLU True\n",
            "80 DepthwiseConv2D True\n",
            "81 BatchNormalization True\n",
            "82 ReLU True\n",
            "83 Conv2D True\n",
            "84 BatchNormalization True\n",
            "85 ReLU True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def addTopModelMobileNet(bottom_model, num_classes):\n",
        "    \"\"\"creates the top or head of the model that will be\n",
        "    placed ontop of the bottom layers\"\"\"\n",
        "\n",
        "    top_model = bottom_model.output\n",
        "    top_model = GlobalAveragePooling2D()(top_model)\n",
        "    top_model = Dense(1024,activation='relu')(top_model)\n",
        "\n",
        "    top_model = Dense(1024,activation='relu')(top_model)\n",
        "\n",
        "    top_model = Dense(512,activation='relu')(top_model)\n",
        "\n",
        "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
        "\n",
        "    return top_model\n"
      ],
      "metadata": {
        "id": "l-DaLEB8qc8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "\n",
        "FC_Head = addTopModelMobileNet(MobileNet, num_classes)\n",
        "\n",
        "model = Model(inputs = MobileNet.input, outputs = FC_Head)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "ZqwwoERcqhk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/gdrive/MyDrive/Autism_model_training/autistic_detection_by_emotion/Dataset/trainData'\n",
        "validation_data_dir = '/content/gdrive/MyDrive/Autism_model_training/autistic_detection_by_emotion/Dataset/validationData'\n"
      ],
      "metadata": {
        "id": "KXpmdfezql81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=30,\n",
        "                    width_shift_range=0.3,\n",
        "                    height_shift_range=0.3,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest'\n",
        "                                   )\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "vVb0APS2q6j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "                        train_data_dir,\n",
        "                        target_size = (img_rows,img_cols),\n",
        "                        batch_size = batch_size,\n",
        "                        class_mode = 'categorical'\n",
        "                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spV5IkDdq7zc",
        "outputId": "8fb88c21-b682-43e5-815b-3b3a67dadc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 250 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                            validation_data_dir,\n",
        "                            target_size=(img_rows,img_cols),\n",
        "                            batch_size=batch_size,\n",
        "                            class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoDrS2myq_iS",
        "outputId": "b5a0b992-4dde-404a-da43-251f8c333e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 250 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "kr-BmvhhrDm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "                             'emotion_face_mobilNet.h5',\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n"
      ],
      "metadata": {
        "id": "MhuU5CIurGzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop = EarlyStopping(\n",
        "                          monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=10,\n",
        "                          verbose=1,restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "sgGV174RrJjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                            patience=5,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.2,\n",
        "                                            min_lr=0.0001)\n",
        "\n",
        "callbacks = [earlystop,checkpoint,learning_rate_reduction]\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "nb_train_samples = 24176\n",
        "nb_validation_samples = 3006\n",
        "\n",
        "epochs = 25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uxdkW5IrMM4",
        "outputId": "6a0d4690-cdbe-488d-d24e-58fa8c9618cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            steps_per_epoch=nb_train_samples//batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=validation_generator,\n",
        "            validation_steps=nb_validation_samples//batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHvT65F6rRQ4",
        "outputId": "d8017b1e-ecdd-41a2-f642-b8b3f47c0f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-11b908ec1b83>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "  8/755 [..............................] - ETA: 1:54:54 - loss: 2.5355 - accuracy: 0.2120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 18875 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 93 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 2.58387, saving model to emotion_face_mobilNet.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r755/755 [==============================] - 190s 210ms/step - loss: 2.5355 - accuracy: 0.2120 - val_loss: 2.5839 - val_accuracy: 0.2000 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/Autism_model_training/autistic_detection_by_emotion/test.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy3Im0GDsQhi",
        "outputId": "7bec40fb-d0ae-4d35-c102-f77a388d5d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}